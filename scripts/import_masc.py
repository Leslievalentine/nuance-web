import os
import psycopg2
from glob import glob

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MASC_PATH = os.path.join(BASE_DIR, 'data', 'MASC', 'data')

DB_CONFIG = {
    "dbname": "nuance_engine_db", "user": "postgres", "password": "5432", 
    "host": "localhost", "options": "-c client_encoding=utf8"
}

def get_masc_genre(filepath):
    """
    ÈÄöËøáÁà∂Êñá‰ª∂Â§πÂêçËé∑ÂèñÂàÜÁ±ª (‰æãÂ¶Ç .../data/written/twitter/abc.txt -> twitter)
    """
    try:
        # Ëé∑ÂèñÊñá‰ª∂ÊâÄÂú®ÁöÑÁõÆÂΩïÂêç
        dirname = os.path.basename(os.path.dirname(filepath))
        # Â¶ÇÊûúÁõ¥Êé•Âú® written/spoken ‰∏ãÔºåÂèØËÉΩË¶ÅÂêë‰∏äÊâæ‰∏ÄÁ∫ßÔºåËøôÈáåÂÅáËÆæ MASC ÁªìÊûÑÊ†áÂáÜ
        return dirname
    except:
        return 'Unclassified'

def clean_masc_text(text):
    # MASC Â∞§ÂÖ∂ twitter ÂåÖÂê´Â§ßÈáèÂûÉÂúæÂ≠óÁ¨¶ÔºåÂÅöÊúÄÂü∫Á°ÄÊ∏ÖÊ¥ó
    # ÊõøÊç¢ÊéâÈùûÊâìÂç∞Â≠óÁ¨¶
    return text.replace('\x00', '').strip()

def import_masc():
    print("üá∫üá∏ [MASC] ÂºÄÂßãÂØºÂÖ•Áé∞‰ª£/ÁΩëÁªúËØ≠Êñô...")
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    
    files = glob(os.path.join(MASC_PATH, '**', '*.txt'), recursive=True)
    print(f"üìö ÂèëÁé∞ {len(files)} ‰∏™ TXT Êñá‰ª∂")
    
    buffer = []
    total_saved = 0
    
    for i, fpath in enumerate(files):
        fid = os.path.basename(fpath)
        if fid.startswith('.'): continue # ÂøΩÁï•ÈöêËóèÊñá‰ª∂
        
        genre = get_masc_genre(fpath)
        
        try:
            with open(fpath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                
            # MASC Ê≤°Êúâ XML Ê†áÁ≠æÔºåÊàë‰ª¨ÊåâÊç¢Ë°åÁ¨¶ÁÆÄÂçïÂàÜÂè•
            # ÂøΩÁï•ËøáÁü≠ÁöÑË°å
            lines = [clean_masc_text(l) for l in content.split('\n') if len(l.split()) > 3]
            
            for line in lines:
                words_arr = [w.lower() for w in line.split() if w.isalnum()]
                if not words_arr: continue
                
                buffer.append((line, words_arr, 'MASC', genre, fid))
                
            if len(buffer) >= 2000:
                args = ','.join(cur.mogrify("(%s,%s,%s,%s,%s)", x).decode('utf-8') for x in buffer)
                cur.execute(f"INSERT INTO corpus_sentences (sentence_text, words_array, source_corpus, original_genre, file_id) VALUES {args}")
                conn.commit()
                total_saved += len(buffer)
                buffer = []
                print(f"\r‚è≥ MASC ËøõÂ∫¶: {i}/{len(files)} | Â∑≤Â≠ò: {total_saved}", end="")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Ë∑≥Ëøá {fid}: {e}")

    if buffer:
        args = ','.join(cur.mogrify("(%s,%s,%s,%s,%s)", x).decode('utf-8') for x in buffer)
        cur.execute(f"INSERT INTO corpus_sentences (sentence_text, words_array, source_corpus, original_genre, file_id) VALUES {args}")
        conn.commit()

    print(f"\n‚úÖ MASC ÂØºÂÖ•ÂÆåÊàê„ÄÇ")
    cur.close(); conn.close()

if __name__ == "__main__":
    import_masc()
